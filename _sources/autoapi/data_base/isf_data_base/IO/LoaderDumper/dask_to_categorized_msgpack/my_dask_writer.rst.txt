
.. backlink:

:mod:`data_base` ❭ :mod:`~data_base.isf_data_base` ❭ :mod:`~data_base.isf_data_base.IO` ❭ :mod:`~data_base.isf_data_base.IO.LoaderDumper` ❭ :mod:`~data_base.isf_data_base.IO.LoaderDumper.dask_to_categorized_msgpack` ❭ :mod:`~data_base.isf_data_base.IO.LoaderDumper.dask_to_categorized_msgpack.my_dask_writer`


.. title:

my_dask_writer
==============


.. py:function:: data_base.isf_data_base.IO.LoaderDumper.dask_to_categorized_msgpack.my_dask_writer(ddf, path, optimize_graph=False, categorize=True, client=None)

   Very simple method to store a dask dataframe to a bunch of files.
   There was a lot of frustration with the respective dask method, which has some weired hard-to-reproduce issues, e.g. it sometimes
   takes all the ram (512GB!) or takes a very long time to "optimize" / merge the graph.

   Update: this issue was addressed here:
   https://github.com/dask/dask/issues/1888


.. 
   Warning: we replace underscores with an escape backslash about 4 lines above to avoid having Sphinx interpret arguments as links.
   However, this may cause issues with code blocks or other literal text, and malform markdown tables
   Use with caution?
..