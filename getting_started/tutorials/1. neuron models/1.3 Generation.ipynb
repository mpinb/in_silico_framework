{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating biophysically detailed multi-compartmental models\n",
    "\n",
    "This tutorial provides a walkthrough on how to use ISF in order to generate biophysically detailed multi-comparmental models that are consistent with empirical responses. To do this, you will need:\n",
    "\n",
    "1. A neuron morphology in the `.hoc` format.\n",
    "2. Empirical data on the neuron's biophysical expression.\n",
    "3. Empirical constraints on the electrophysiological response to input stimuli.\n",
    "\n",
    "ISF provides two ways of generating multi-compartmental neuron models:\n",
    "\n",
    "\n",
    "|   |Algorithm | Pros | Cons\n",
    "|---|---|---|---|\n",
    "|1.|[Multi-Objective Evolutionary Algorithm (MOEA)](../../../biophysics_fitting/MOEA_EH_minimal/__init__.py) | No a priori requirements | Does not explore the full diversity of possible BDMs|\n",
    "|2.|[Exploration algorithm](../../../biophysics_fitting/exploration_from_seedpoint/__init__.py) | Explores the full biophysical diversity of possible BDMs | Requires a seedpoint|\n",
    "\n",
    "Below, we go over an example on how to generate neuron models using both approaches for a Layer 5 Pyramidal Tract (L5PT) neuron. Let's set up a database for the results generated during this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Interface as I\n",
    "from getting_started import getting_started_dir, tutorial_output_dir\n",
    "\n",
    "example_data_dir = I.os.path.join(getting_started_dir, 'example_data')\n",
    "db = I.DataBase(tutorial_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Objective Evolutionary Algorithm\n",
    "\n",
    "This section will guide you through using ISF to create neuron models from scratch using a Multi-Objective Evolutionary Optimization algorithm (MOEA) called [BluePyOpt](https://github.com/BlueBrain/BluePyOpt).\n",
    "\n",
    "### Empirical limits for biophysical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biophysics_fitting.hay_complete_default_setup import get_feasible_model_params\n",
    "\n",
    "params = get_feasible_model_params().drop('x', axis=1)\n",
    "params.index = [e.replace('CaDynamics_E2', 'CaDynamics_E2_v2') for e in params.index]\n",
    "params.index = 'ephys.' + params.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the conductance of the ion channels, two important free parameters need to be added in order to find models for an L5PT:\n",
    "- The spatial distribution of $SK_V3.1$ channels along the apical dendrite. These are modeled here to slope off from the soma towards the end of the apical dendrite, consistent with Schaefer et al. (2007) (https://doi.org/10.1113/jphysiol.2006.122564)\n",
    "\n",
    "- The thickness of the apical dendrite. Why this is added as a free parameter is explained in [this auxiliary notebook](../auxiliary%20notebooks/A.0%20The%20Barrel%20Cortex.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params.append(\n",
    "    I.pd.DataFrame({\n",
    "        'ephys.SKv3_1.apic.slope': {\n",
    "            'min': -3,\n",
    "            'max': 0\n",
    "        },\n",
    "        'ephys.SKv3_1.apic.offset': {\n",
    "            'min': 0,\n",
    "            'max': 1\n",
    "        }\n",
    "    }).T)\n",
    "params = params.append(\n",
    "    I.pd.DataFrame({\n",
    "        'min': .333,\n",
    "        'max': 3\n",
    "    }, index=['scale_apical.scale']))\n",
    "\n",
    "\n",
    "params = params.sort_index()\n",
    "print(\"Empirical limits for biological parameters\")\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MOEA algorithm expects a database containing methods that set up Simulator and Evaluator objects. Let's create these methods.\n",
    "Here, you can set up which input stimuli will be run, and how they will be evaluated. We have already created such simulation setup and evaluation methods for L5PTs consisten with [Hay et al. (2011)](https://doi.org/10.1371/journal.pcbi.1002107\n",
    ") in [hay_complete_default_setup](../../../biophysics_fitting/hay_complete_default_setup.py) and [L5tt_parameter_setup](../../../biophysics_fitting/L5tt_parameter_setup.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biophysics_fitting.L5tt_parameter_setup import get_L5tt_template_v2\n",
    "import biophysics_fitting.hay_complete_default_setup as hay_setup\n",
    "\n",
    "def scale_apical(cell_param, params):\n",
    "    assert(len(params) == 1)\n",
    "    cell_param.cell_modify_functions.scale_apical.scale = params['scale']\n",
    "    return cell_param\n",
    "\n",
    "def get_fixed_params(db_setup):\n",
    "    \"\"\"\n",
    "    Configure the fixed params and return\n",
    "    \"\"\"\n",
    "    fixed_params = db_setup['fixed_params']\n",
    "    fixed_params['morphology.filename'] = db_setup['morphology'].get_file(\n",
    "        'hoc')\n",
    "    return fixed_params\n",
    "\n",
    "def get_Simulator(db_setup, step=False):\n",
    "    \"\"\"\n",
    "    Configure the Simulator object and return\n",
    "    \"\"\"\n",
    "    fixed_params = db_setup['get_fixed_params'](db_setup)\n",
    "    s = hay_setup.get_Simulator(\n",
    "        I.pd.Series(fixed_params),\n",
    "        step=step)\n",
    "    s.setup.cell_param_generator = get_L5tt_template_v2\n",
    "    s.setup.cell_param_modify_funs.append(\n",
    "        ('scale_apical', scale_apical)\n",
    "        )\n",
    "    s.setup.params_modify_funs_after_cell_generation = []\n",
    "    return s\n",
    "\n",
    "def get_Evaluator(db_setup, step=False):\n",
    "    \"\"\"\n",
    "    No additional configuration is needed for the Evaluator, simply return biophysics_fitting.L5tt_parameter_setup.get_Evaluator\n",
    "    \"\"\"\n",
    "    return hay_setup.get_Evaluator(step=step)\n",
    "\n",
    "def get_Combiner(db_setup, step=False):\n",
    "    \"\"\"\n",
    "    No additional configuration is needed for the Combiner, simply return biophysics_fitting.L5tt_parameter_setup.get_Combiner\n",
    "    \"\"\"\n",
    "    return hay_setup.get_Combiner(step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the database for optimization can be set up as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_db_for_MOEA(db, morphology_id='89', morphology=\"\", step=False):\n",
    "    \"\"\"\n",
    "    Set up a DataBase for MOEA.\n",
    "\n",
    "    Args:\n",
    "        db: a DataBase object\n",
    "        morphology_id: name of the morphology\n",
    "        morphology: path to a .hoc morphology file\n",
    "        step: whether or not to perform step current injections\n",
    "\n",
    "    Returns:\n",
    "        data_base.DataBase: a database containing:\n",
    "            - fixed_params\n",
    "            - get_fixed_params\n",
    "            - get_Simulator\n",
    "            - get_Evaluator\n",
    "            - get_Combiner\n",
    "            - the morphology file\n",
    "    \"\"\"\n",
    "    from data_base.IO.LoaderDumper import pandas_to_pickle, to_cloudpickle\n",
    "    db.create_sub_db(morphology_id)\n",
    "\n",
    "    db[morphology_id].create_managed_folder('morphology')\n",
    "    I.shutil.copy(\n",
    "        I.os.path.join(\n",
    "            morphology\n",
    "        ), db[morphology_id]['morphology'].join(\n",
    "            morphology.split(I.os.sep)[-1]\n",
    "        ))\n",
    "\n",
    "    db[morphology_id]['fixed_params'] = {\n",
    "        'BAC.hay_measure.recSite': 294.8203371921156,   # recording site on the apical dendrite for BAC\n",
    "        'BAC.stim.dist': 294.8203371921156,             # stimulus injection site on the apical dendrite for BAC\n",
    "        'bAP.hay_measure.recSite1': 294.8203371921156,  # recording site 1 on the apical dendrite for bAP\n",
    "        'bAP.hay_measure.recSite2': 474.8203371921156,  # recording site 2 on the apical dendrite for bAP\n",
    "        'hot_zone.min_': 384.8203371921156,             # calcium zone start\n",
    "        'hot_zone.max_': 584.8203371921156,             # calcium zone end\n",
    "        'hot_zone.outsidescale_sections': [23,24,25,26,27,28,29,31,32,33,34,35,37,38,40,42,43,44,46,48,50,51,52,54,56,58,60],\n",
    "        'morphology.filename': None\n",
    "        }\n",
    "\n",
    "    db[morphology_id]['get_fixed_params'] = get_fixed_params\n",
    "    db[morphology_id].set('params', params, dumper=pandas_to_pickle)\n",
    "    db[morphology_id].set('get_Simulator',\n",
    "                      I.partial(get_Simulator, step=step),\n",
    "                      dumper=to_cloudpickle)\n",
    "    db[morphology_id].set('get_Evaluator',\n",
    "                      I.partial(get_Evaluator, step=step),\n",
    "                      dumper=to_cloudpickle)\n",
    "    db[morphology_id].set('get_Combiner',\n",
    "                      I.partial(get_Combiner, step=step),\n",
    "                      dumper=to_cloudpickle)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy over a morphology and initialize our DataBase for the optimization run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology_path = I.os.path.join(\n",
    "    example_data_dir, \n",
    "    \"anatomical_constraints\", \n",
    "    \"89_L5_CDK20050712_nr6L5B_dend_PC_neuron_transform_registered_C2.hoc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = set_up_db_for_MOEA(\n",
    "    db,\n",
    "    morphology_id=\"89\",\n",
    "    morphology=morphology_path,\n",
    "    step=False\n",
    "    )\n",
    "db.ls(max_lines_per_key=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to run the optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedpoint = 42\n",
    "\n",
    "population = I.bfit_start_run(\n",
    "    db['89'], \n",
    "    n=seedpoint,\n",
    "    client=I.get_client(), \n",
    "    offspring_size=10,      # Low amount of offspring just as an example \n",
    "    pop=None,               # adapt this to the output population of the previous run to continue where you left off\n",
    "    continue_cp=False,      # If you want to continue a preivoius run, set to True\n",
    "    max_ngen=1              # run for just 1 generation\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are written out after each generation. We have an offspring size of $10$, so we will find 10 proposed biophysical models in generation $1$ of our seedpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the optimizer results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the optimization algorithm did not run for very long, they likely will not produce very good results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = db['89'][str(seedpoint)]['1']\n",
    "objectives = population.drop(params.index, axis=1)\n",
    "objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most values are about $250 \\sigma$ removed from the empirical mean, but some objectives are already quite close!\n",
    "What is the spread on the empirical data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biophysics_fitting.hay_complete_default_setup import get_hay_problem_description\n",
    "empirical_data = get_hay_problem_description()\n",
    "empirical_data = empirical_data[empirical_data['objective'] \\\n",
    "                                .isin(objectives.columns)] \\\n",
    "                                .set_index(\"objective\") \\\n",
    "                                .loc[objectives.columns]\n",
    "print(\"Empirical distribution for physiology objectives\")\n",
    "empirical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $250\\ \\sigma$ is obviously quite far away from the empirical data. Then again, the model did not run for very long.\n",
    "In general, the initial models proposed by the evolutionary algorithm do not do reproduce empirically observed responses, and are quite far off. It takes a lot more than an offspring size of $10$ and a single generation to get close to a model that reproduces empirically observed responses.\n",
    "\n",
    "To finalize the optimization, let's see how many of the objectives got close to the empirical mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "I.plt.style.use(\"fivethirtyeight\")\n",
    "diff = (objectives - empirical_data['mean']) / empirical_data[\"std\"]\n",
    "ax = diff.plot.box(vert=False)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(\"amount of $\\sigma$ from empirical mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [the previous tutorial](./1.2%20Evaluation.ipynb) for more information on how to evaluate biophysically detailed single-cell models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration from seedpoint\n",
    "\n",
    "Assuming that we have a biophysical model that performs well on **all** objectives, it is possible to continuously make variations on the biophysical parameters while keeping the objectives in-distribution.\n",
    "\n",
    "This is conveniently packaged in [`biophysics_fitting.exploration_from_seedpoint`](../../../biophysics_fitting/exploration_from_seedpoint/__init__.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not I.os.path.exists(I.os.path.join(db[\"89\"].basedir, 'RW_exploration_example')):\n",
    "    db[\"89\"].create_managed_folder('RW_exploration_example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide some working models for this morphology below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db[\"example_models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the random walk exploration\n",
    "\n",
    "there are many different kinds of exploration one could do. We will simply use a random walk, as it has proven to be both efficient and capable of broadly sampling the bipohysical parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = db[\"89\"][\"get_Evaluator\"](db['89'])\n",
    "simulator = db[\"89\"][\"get_Simulator\"](db['89'])\n",
    "biophysical_parameter_ranges = db['89']['params']\n",
    "example_models = db['example_models']\n",
    "biophysical_parameter_names = [e for e in example_models.columns if \"ephys\" in e or e == \"scale_apical.scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biophysics_fitting.exploration_from_seedpoint.RW import RW\n",
    "from biophysics_fitting.exploration_from_seedpoint.utils import evaluation_function_incremental_helper\n",
    "from biophysics_fitting.hay_evaluation import hay_evaluate_bAP, hay_evaluate_BAC\n",
    "\n",
    "evaluation_function = I.partial(\n",
    "    evaluation_function_incremental_helper,  # this incremental helper stops the evaluation as soon as a stimulus protocol doesn't work.\n",
    "    s=simulator,\n",
    "    e=evaluator,\n",
    "    stim_order=['bAP', 'BAC']\n",
    ")\n",
    "\n",
    "rw = RW(\n",
    "    param_ranges = biophysical_parameter_ranges,\n",
    "    df_seeds = example_models[biophysical_parameter_names],\n",
    "    evaluation_function = evaluation_function,\n",
    "    MAIN_DIRECTORY = db[\"89\"]['RW_exploration_example'],\n",
    "    min_step_size = 0.02,\n",
    "    max_step_size = 0.02,\n",
    "    checkpoint_every = 1  # This is a lot of IO. Increase this value if you are not merely doing an example.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the exploration algorithm\n",
    "\n",
    "Let's run this for 20 seconds. You can always restart the exploration and it will pick up from where it left off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duration = 30  # in seconds\n",
    "\n",
    "from time import sleep\n",
    "from threading import Thread\n",
    "import multiprocessing\n",
    "\n",
    "proc = multiprocessing.Process(\n",
    "    target=rw.run_RW, \n",
    "    kwargs={\n",
    "        'selected_seedpoint': 0,\n",
    "        'particle_id': 0,\n",
    "        'seed': 42  # for numpy random seed\n",
    "    })\n",
    "\n",
    "# --- run for some time, then kill the process\n",
    "proc.start()\n",
    "sleep(duration)\n",
    "proc.terminate()  # sends a SIGTERM\n",
    "proc.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biophysics_fitting.exploration_from_seedpoint.RW_analysis import Load\n",
    "\n",
    "outdir = db[\"89\"]['RW_exploration_example'].join('0')\n",
    "l = Load(\n",
    "    I.get_client(),\n",
    "    outdir,\n",
    "    n_particles = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explored_models = l.get_df().compute()\n",
    "print(\"Explored {} new models\".format(len(explored_models)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the exploration results\n",
    "\n",
    "How much did the exploration actually explore? Let's plot out how much it deviated from it's starting point, relative to the total extent of parameter limits we allowed for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, mn, mx):\n",
    "    return (df - mn)/(mx-mn)\n",
    "    \n",
    "mn, mx = biophysical_parameter_ranges['min'], biophysical_parameter_ranges['max']\n",
    "normalized_startpoint = normalize(example_models.iloc[0][biophysical_parameter_names], mn, mx)\n",
    "normalized_explored_models = normalize(explored_models[biophysical_parameter_names], mn, mx)\n",
    "\n",
    "# calc exploration relative to startpoint, in % of total allowed parameter limits\n",
    "d = I.pd.concat([normalized_explored_models, I.pd.DataFrame(normalized_startpoint).T])\n",
    "d -= normalized_startpoint\n",
    "d[biophysical_parameter_names] *= 100\n",
    "d = d.melt(var_name='Biophysical parameter', value_name='Normalized value (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I.plt.figure(figsize=(5, 10))\n",
    "\n",
    "ax = I.sns.boxplot(\n",
    "    data=d,\n",
    "    y='Biophysical parameter', x='Normalized value (%)',\n",
    "    whis=100,\n",
    "    linewidth=1,\n",
    "    showcaps = False\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what the resulting voltage traces look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayeds = [\n",
    "    I.dask.delayed(simulator.run)(p, 'BAC') \n",
    "    for _, p in explored_models[biophysical_parameter_names].iterrows()\n",
    "    ]\n",
    "f = I.get_client().compute(delayeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [f_.result() for f_ in f]\n",
    "BAC_responses = [response['BAC.hay_measure'] for response in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_voltages = [\n",
    "    e['vList'][0] for e in BAC_responses\n",
    "]\n",
    "dend_voltages = [\n",
    "    e['vList'][1] for e in BAC_responses\n",
    "]\n",
    "time_points = [\n",
    "    e['tVec'] for e in BAC_responses\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = I.plt.subplots(1, 2, figsize=(15, 5))\n",
    "colors = I.plt.rcParams['axes.prop_cycle'].by_key()['color']                       \n",
    "random_model = I.np.random.randint(0, len(BAC_responses))\n",
    "print(\"Highlighting model nr. {}\".format(random_model))\n",
    "\n",
    "for t, v in zip(time_points, soma_voltages):\n",
    "    ax1.plot(t, v, c=\"silver\", lw=3)\n",
    "ax1.plot(\n",
    "    time_points[random_model], \n",
    "    soma_voltages[random_model], \n",
    "    c=colors[0],\n",
    "    lw=2\n",
    "    )\n",
    "ax1.set_title(\"Soma voltage\")\n",
    "ax1.set_xlabel(\"Time (ms)\")\n",
    "ax1.set_ylabel(\"Membrane voltage (mV)\")\n",
    "\n",
    "for t, v in zip(time_points, dend_voltages ):\n",
    "    ax2.plot(t, v, c='silver', lw=3)\n",
    "ax2.plot(\n",
    "    time_points[random_model], \n",
    "    dend_voltages[random_model], \n",
    "    c=colors[1],\n",
    "    lw=2\n",
    "    )\n",
    "ax2.set_title(\"Dendritic voltage\")\n",
    "ax2.set_xlabel(\"Time (ms)\")\n",
    "I.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell, _ = simulator.get_simulated_cell(\n",
    "    explored_models[biophysical_parameter_names].iloc[random_model], \n",
    "    \"BAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize.cell_morphology_visualizer import CellMorphologyVisualizer as CMV\n",
    "\n",
    "CMV(\n",
    "    cell,\n",
    "    t_start=250,\n",
    "    t_stop=400,\n",
    "    t_step=1,\n",
    "    ).animation(\n",
    "    images_path=db.basedir+'/images',\n",
    "    color=\"voltage\",\n",
    "    client=I.get_client(),\n",
    "    show_legend=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
