{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding a neuron model in a network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial guides the user through how to use ISF to embed a neuron model in a dense connectome model, mapping synapses onto a neuron morphology based on empirical data. We provide a network modeling pipeline that has been described in detail in [Udvary et al. (2022)](https://doi.org/10.1016/j.celrep.2022.110677). \n",
    "\n",
    "To generate such synapse maps from scratch, the user must download the [barrel cortex model](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/JZPULN) from harvard Dataverse:\n",
    "\n",
    "```shell\n",
    "pixi run download_bc_model\n",
    "```\n",
    "\n",
    "To get started, adapt the desired output directory below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "tutorial_output_dir = f\"{Path.home()}/isf_tutorial_output\"  # <-- Change this to your desired output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ISF: Loading mechanisms:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no DISPLAY environment variable.\n",
      "--No graphics will be displayed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ISF: Current version: heads/docs+0.gbd24993f.dirty\n",
      "[INFO] ISF: Current pid: 49082\n",
      "[ATTENTION] ISF: The source folder has uncommited changes!\n",
      "\n",
      "\n",
      "\n",
      "[INFO] ISF: Loaded modules with __version__ attribute are:\n",
      "IPython: 8.12.2, Interface: heads/docs+0.gbd24993f.dirty, PIL: 10.4.0, _brotli: 1.0.9, _csv: 1.0, _ctypes: 1.1.0, _curses: b'2.2', _decimal: 1.70, argparse: 1.1, backcall: 0.2.0, blosc: 1.11.1, bluepyopt: 1.9.126, brotli: 1.0.9, certifi: 2024.08.30, cffi: 1.17.0, charset_normalizer: 3.4.0, click: 7.1.2, cloudpickle: 3.1.0, colorama: 0.4.6, comm: 0.2.2, csv: 1.0, ctypes: 1.1.0, cycler: 0.12.1, cytoolz: 0.12.3, dash: 2.18.2, dask: 2.30.0, dateutil: 2.9.0, deap: 1.4, debugpy: 1.8.5, decimal: 1.70, decorator: 5.1.1, defusedxml: 0.7.1, distributed: 2.30.0, distutils: 3.8.20, django: 1.8.19, entrypoints: 0.4, executing: 2.1.0, fasteners: 0.17.3, flask: 1.1.4, fsspec: 2024.10.0, future: 1.0.0, greenlet: 3.1.1, idna: 3.10, ipaddress: 1.0, ipykernel: 6.29.5, ipywidgets: 8.1.5, itsdangerous: 1.1.0, jedi: 0.19.1, jinja2: 2.11.3, joblib: 1.4.2, json: 2.0.9, jupyter_client: 7.3.4, jupyter_core: 5.7.2, kiwisolver: 1.4.5, logging: 0.5.1.2, markupsafe: 2.0.1, matplotlib: 3.5.1, msgpack: 1.0.8, neuron: 7.8.2+, numcodecs: 0.12.1, numexpr: 2.8.6, numpy: 1.19.2, packaging: 24.2, pandas: 1.1.3, pandas_msgpack: 0.1.4+14.gfcb0471.dirty, parameters: 0.2.1, parso: 0.8.4, past: 1.0.0, pexpect: 4.9.0, pickleshare: 0.7.5, platform: 1.0.8, platformdirs: 4.3.6, plotly: 5.24.1, prompt_toolkit: 3.0.48, psutil: 6.0.0, ptyprocess: 0.7.0, pure_eval: 0.2.3, pydevd: 2.9.5, pygments: 2.18.0, pyparsing: 3.1.4, pytz: 2024.2, re: 2.2.1, requests: 2.32.3, scandir: 1.10.0, scipy: 1.5.2, seaborn: 0.12.2, six: 1.16.0, sklearn: 0.23.2, socketserver: 0.4, socks: 1.7.1, sortedcontainers: 2.4.0, stack_data: 0.6.2, statsmodels: 0.13.2, sumatra: 0.7.4, tables: 3.8.0, tblib: 3.0.0, tlz: 0.12.3, toolz: 1.0.0, traitlets: 5.14.3, urllib3: 2.2.3, wcwidth: 0.2.13, werkzeug: 1.0.1, yaml: 5.3.1, zarr: 2.15.0, zlib: 1.0, zmq: 26.2.0, zstandard: 0.23.0\n"
     ]
    }
   ],
   "source": [
    "import Interface as I\n",
    "from getting_started import getting_started_dir\n",
    "example_data_dir = I.os.path.join(getting_started_dir, 'example_data')\n",
    "db = I.DataBase(tutorial_output_dir).create_sub_db(\"network_modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Register the cell morphology in the desired reference frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to embedding a neuron model into a network model, is to align the reference frames of both.\n",
    "\n",
    "From external resources (e.g. the NeuroMorph pipeline), you need a morphology `.hoc`-file. The coordinates in the hoc morphology file need to be anchored at the desired location.\n",
    "\n",
    "As an example, we already provide such file of a Layer-5 Pyramidal Tract Neuron (L5PT) whose coordinates are anchored in the C2 column of a rat barrel cortex (BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center_synapses_20150504-1611_10389',\n",
       " '89_L5_CDK20050712_nr6L5B_dend_PC_neuron_transform_registered_C2.hoc',\n",
       " '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center.hoc',\n",
       " '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center.swc',\n",
       " '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center_scaled_diameters.hoc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.os.listdir(\n",
    "    I.os.path.join(\n",
    "        getting_started_dir, \n",
    "        'example_data', \n",
    "        'anatomical_constraints'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_hoc = I.os.path.join(\n",
    "    getting_started_dir, \n",
    "    'example_data', \n",
    "    'anatomical_constraints',\n",
    "    '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center.hoc')\n",
    "path_to_scaled_hoc = I.os.path.join(\n",
    "    getting_started_dir, \n",
    "    'example_data', \n",
    "    'anatomical_constraints', \\\n",
    "    '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center_scaled_diameters.hoc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copy these morphology files to our DataBase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'anatomical_constraints' in db.keys():\n",
    "    db.create_managed_folder('anatomical_constraints')\n",
    "    I.shutil.copy(path_to_hoc, db['anatomical_constraints'])\n",
    "    I.shutil.copy(path_to_scaled_hoc, db['anatomical_constraints'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: calculate positions of anatomical synapses with respect to the registered morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [`singlecell_input_mapper`](../singlecell_input_mapper/readme.md) to create an anatomical model of how that cell is integrated in the brain are (here: the barrel cortex). For more information on how this is done, see [Egger et al. 2014](https://www.frontiersin.org/articles/10.3389/fnana.2014.00129/full). This module creates an anatomical reconstruction of axo-dendritic connections depending on the spatial distribution of cells, bouton density, and anatomical constraints of post-synaptic targets of the postsynaptic cell, such as morphology and synapse density. To do so, it needs the following input:\n",
    "1. The neuron morphology (the `.hoc` file that we already copied over)\n",
    "2. Density of total Post-Synaptic Target sites (PST) across the dendritic tree of the postynaptic cell (used for normalization)\n",
    "3. Anatomical constraints of PSTs: the amount of synapses per length unit and area unit, depending on pre- and post-synaptic celltype, and the location along the dendritic tree of the postsynaptic cell. These are normalized using the previously mentioned PST densities.\n",
    "4. Bouton densities across the entire brain area of interest.\n",
    "5. Spatial distribution of cells, depending on their type.\n",
    "\n",
    "Under the hood, multiple anatomical realizations will be computed, all of which consistent with the input data. \n",
    "From this distribution of anatomical realizations, the one that is closest to the average is chosen, which can be refered to as a \"representative realization\". The result is saved in the same folder as the hoc morphology. This takes about 4 hrs to compute, but you can continue with a precomputed result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute it yourself, run the cell below. To copy a precomputed result, you can skip to the next code cell\n",
    "\n",
    "Here, we only use 2 samples. This is generally not enough to get a sufficiently large distribution to draw a representative sample from. It is however sufficient for the sake of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading hoc file /gpfs/soma_fs/home/meulemeester/isf_tutorial_output/network_modeling/db/anatomical_constraints/86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center.hoc\n",
      "---------------------------\n",
      "Computing 3D length/surface area density of structures with label Soma\n",
      "Computing 3D length/surface area density of structures with label Dendrite\n",
      "0 of 181 done...\n",
      "1 of 181 done...\n",
      "2 of 181 done...\n",
      "3 of 181 done...\n",
      "4 of 181 done...\n",
      "5 of 181 done...\n",
      "6 of 181 done...\n",
      "7 of 181 done...\n",
      "8 of 181 done...\n",
      "9 of 181 done...\n",
      "10 of 181 done...\n",
      "11 of 181 done...\n",
      "12 of 181 done...\n",
      "13 of 181 done...\n",
      "14 of 181 done...\n",
      "15 of 181 done...\n",
      "16 of 181 done...\n",
      "17 of 181 done...\n",
      "18 of 181 done...\n",
      "19 of 181 done...\n",
      "20 of 181 done...\n",
      "21 of 181 done...\n",
      "22 of 181 done...\n",
      "23 of 181 done...\n",
      "24 of 181 done...\n",
      "25 of 181 done...\n",
      "26 of 181 done...\n",
      "27 of 181 done...\n",
      "28 of 181 done...\n",
      "29 of 181 done...\n",
      "30 of 181 done...\n",
      "31 of 181 done...\n",
      "32 of 181 done...\n",
      "33 of 181 done...\n",
      "34 of 181 done...\n",
      "35 of 181 done...\n",
      "36 of 181 done...\n",
      "37 of 181 done...\n",
      "38 of 181 done...\n",
      "39 of 181 done...\n",
      "40 of 181 done...\n",
      "41 of 181 done...\n",
      "42 of 181 done...\n",
      "43 of 181 done...\n",
      "44 of 181 done...\n",
      "45 of 181 done...\n",
      "46 of 181 done...\n",
      "47 of 181 done...\n",
      "48 of 181 done...\n",
      "49 of 181 done...\n",
      "50 of 181 done...\n",
      "51 of 181 done...\n",
      "52 of 181 done...\n",
      "53 of 181 done...\n",
      "54 of 181 done...\n",
      "55 of 181 done...\n",
      "56 of 181 done...\n",
      "57 of 181 done...\n",
      "58 of 181 done...\n",
      "59 of 181 done...\n",
      "60 of 181 done...\n",
      "61 of 181 done...\n",
      "62 of 181 done...\n",
      "63 of 181 done...\n",
      "64 of 181 done...\n",
      "65 of 181 done...\n",
      "66 of 181 done...\n",
      "67 of 181 done...\n",
      "68 of 181 done...\n",
      "69 of 181 done...\n",
      "70 of 181 done...\n",
      "71 of 181 done...\n",
      "72 of 181 done...\n",
      "73 of 181 done...\n",
      "74 of 181 done...\n",
      "75 of 181 done...\n",
      "76 of 181 done...\n",
      "77 of 181 done...\n",
      "78 of 181 done...\n",
      "79 of 181 done...\n",
      "80 of 181 done...\n",
      "81 of 181 done...\n",
      "82 of 181 done...\n",
      "83 of 181 done...\n",
      "84 of 181 done...\n",
      "85 of 181 done...\n",
      "86 of 181 done...\n",
      "87 of 181 done...\n",
      "88 of 181 done...\n",
      "89 of 181 done...\n",
      "90 of 181 done...\n",
      "91 of 181 done...\n",
      "92 of 181 done...\n",
      "93 of 181 done...\n",
      "94 of 181 done...\n",
      "95 of 181 done...\n",
      "96 of 181 done...\n",
      "97 of 181 done...\n",
      "98 of 181 done...\n",
      "99 of 181 done...\n",
      "100 of 181 done...\n",
      "101 of 181 done...\n",
      "102 of 181 done...\n",
      "103 of 181 done...\n",
      "104 of 181 done...\n",
      "105 of 181 done...\n",
      "106 of 181 done...\n",
      "107 of 181 done...\n",
      "108 of 181 done...\n",
      "109 of 181 done...\n",
      "110 of 181 done...\n",
      "111 of 181 done...\n",
      "112 of 181 done...\n",
      "113 of 181 done...\n",
      "114 of 181 done...\n",
      "115 of 181 done...\n",
      "116 of 181 done...\n",
      "117 of 181 done...\n",
      "118 of 181 done...\n",
      "119 of 181 done...\n",
      "120 of 181 done...\n",
      "121 of 181 done...\n",
      "122 of 181 done...\n",
      "123 of 181 done...\n",
      "124 of 181 done...\n",
      "125 of 181 done...\n",
      "126 of 181 done...\n",
      "127 of 181 done...\n",
      "128 of 181 done...\n",
      "129 of 181 done...\n",
      "130 of 181 done...\n",
      "131 of 181 done...\n",
      "132 of 181 done...\n",
      "133 of 181 done...\n",
      "134 of 181 done...\n",
      "135 of 181 done...\n",
      "136 of 181 done...\n",
      "137 of 181 done...\n",
      "138 of 181 done...\n",
      "139 of 181 done...\n",
      "140 of 181 done...\n",
      "141 of 181 done...\n",
      "142 of 181 done...\n",
      "143 of 181 done...\n",
      "144 of 181 done...\n",
      "145 of 181 done...\n",
      "146 of 181 done...\n",
      "147 of 181 done...\n",
      "148 of 181 done...\n",
      "149 of 181 done...\n",
      "150 of 181 done...\n",
      "151 of 181 done...\n",
      "152 of 181 done...\n",
      "153 of 181 done...\n",
      "154 of 181 done...\n",
      "155 of 181 done...\n",
      "156 of 181 done...\n",
      "157 of 181 done...\n",
      "158 of 181 done...\n",
      "159 of 181 done...\n",
      "160 of 181 done...\n",
      "161 of 181 done...\n",
      "162 of 181 done...\n",
      "163 of 181 done...\n",
      "164 of 181 done...\n",
      "165 of 181 done...\n",
      "166 of 181 done...\n",
      "167 of 181 done...\n",
      "168 of 181 done...\n",
      "169 of 181 done...\n",
      "170 of 181 done...\n",
      "171 of 181 done...\n",
      "172 of 181 done...\n",
      "173 of 181 done...\n",
      "174 of 181 done...\n",
      "175 of 181 done...\n",
      "176 of 181 done...\n",
      "177 of 181 done...\n",
      "178 of 181 done...\n",
      "179 of 181 done...\n",
      "180 of 181 done...\n",
      "Computing 3D length/surface area density of structures with label ApicalDendrite\n",
      "0 of 257 done...\n",
      "1 of 257 done...\n",
      "2 of 257 done...\n",
      "3 of 257 done...\n",
      "4 of 257 done...\n",
      "5 of 257 done...\n",
      "6 of 257 done...\n",
      "7 of 257 done...\n",
      "8 of 257 done...\n",
      "9 of 257 done...\n",
      "10 of 257 done...\n",
      "11 of 257 done...\n",
      "12 of 257 done...\n",
      "13 of 257 done...\n",
      "14 of 257 done...\n",
      "15 of 257 done...\n",
      "16 of 257 done...\n",
      "17 of 257 done...\n",
      "18 of 257 done...\n",
      "19 of 257 done...\n",
      "20 of 257 done...\n",
      "21 of 257 done...\n",
      "22 of 257 done...\n",
      "23 of 257 done...\n",
      "24 of 257 done...\n",
      "25 of 257 done...\n",
      "26 of 257 done...\n",
      "27 of 257 done...\n",
      "28 of 257 done...\n",
      "29 of 257 done...\n",
      "30 of 257 done...\n",
      "31 of 257 done...\n",
      "32 of 257 done...\n",
      "33 of 257 done...\n",
      "34 of 257 done...\n",
      "35 of 257 done...\n",
      "36 of 257 done...\n",
      "37 of 257 done...\n",
      "38 of 257 done...\n",
      "39 of 257 done...\n",
      "40 of 257 done...\n",
      "41 of 257 done...\n",
      "42 of 257 done...\n",
      "43 of 257 done...\n",
      "44 of 257 done...\n",
      "45 of 257 done...\n",
      "46 of 257 done...\n",
      "47 of 257 done...\n",
      "48 of 257 done...\n",
      "49 of 257 done...\n",
      "50 of 257 done...\n",
      "51 of 257 done...\n",
      "52 of 257 done...\n",
      "53 of 257 done...\n",
      "54 of 257 done...\n",
      "55 of 257 done...\n",
      "56 of 257 done...\n",
      "57 of 257 done...\n",
      "58 of 257 done...\n",
      "59 of 257 done...\n",
      "60 of 257 done...\n",
      "61 of 257 done...\n",
      "62 of 257 done...\n",
      "63 of 257 done...\n",
      "64 of 257 done...\n",
      "65 of 257 done...\n",
      "66 of 257 done...\n",
      "67 of 257 done...\n",
      "68 of 257 done...\n",
      "69 of 257 done...\n",
      "70 of 257 done...\n",
      "71 of 257 done...\n",
      "72 of 257 done...\n",
      "73 of 257 done...\n",
      "74 of 257 done...\n",
      "75 of 257 done...\n",
      "76 of 257 done...\n",
      "77 of 257 done...\n",
      "78 of 257 done...\n",
      "79 of 257 done...\n",
      "80 of 257 done...\n",
      "81 of 257 done...\n",
      "82 of 257 done...\n",
      "83 of 257 done...\n",
      "84 of 257 done...\n",
      "85 of 257 done...\n",
      "86 of 257 done...\n",
      "87 of 257 done...\n",
      "88 of 257 done...\n",
      "89 of 257 done...\n",
      "90 of 257 done...\n",
      "91 of 257 done...\n",
      "92 of 257 done...\n",
      "93 of 257 done...\n",
      "94 of 257 done...\n",
      "95 of 257 done...\n",
      "96 of 257 done...\n",
      "97 of 257 done...\n",
      "98 of 257 done...\n",
      "99 of 257 done...\n",
      "100 of 257 done...\n",
      "101 of 257 done...\n",
      "102 of 257 done...\n",
      "103 of 257 done...\n",
      "104 of 257 done...\n",
      "105 of 257 done...\n",
      "106 of 257 done...\n",
      "107 of 257 done...\n",
      "108 of 257 done...\n",
      "109 of 257 done...\n",
      "110 of 257 done...\n",
      "111 of 257 done...\n",
      "112 of 257 done...\n",
      "113 of 257 done...\n",
      "114 of 257 done...\n",
      "115 of 257 done...\n",
      "116 of 257 done...\n",
      "117 of 257 done...\n",
      "118 of 257 done...\n",
      "119 of 257 done...\n",
      "120 of 257 done...\n",
      "121 of 257 done...\n",
      "122 of 257 done...\n",
      "123 of 257 done...\n",
      "124 of 257 done...\n",
      "125 of 257 done...\n",
      "126 of 257 done...\n",
      "127 of 257 done...\n",
      "128 of 257 done...\n",
      "129 of 257 done...\n",
      "130 of 257 done...\n",
      "131 of 257 done...\n",
      "132 of 257 done...\n",
      "133 of 257 done...\n",
      "134 of 257 done...\n",
      "135 of 257 done...\n",
      "136 of 257 done...\n",
      "137 of 257 done...\n",
      "138 of 257 done...\n",
      "139 of 257 done...\n",
      "140 of 257 done...\n",
      "141 of 257 done...\n",
      "142 of 257 done...\n",
      "143 of 257 done...\n",
      "144 of 257 done...\n",
      "145 of 257 done...\n",
      "146 of 257 done...\n",
      "147 of 257 done...\n",
      "148 of 257 done...\n",
      "149 of 257 done...\n",
      "150 of 257 done...\n",
      "151 of 257 done...\n",
      "152 of 257 done...\n",
      "153 of 257 done...\n",
      "154 of 257 done...\n",
      "155 of 257 done...\n",
      "156 of 257 done...\n",
      "157 of 257 done...\n",
      "158 of 257 done...\n",
      "159 of 257 done...\n",
      "160 of 257 done...\n",
      "161 of 257 done...\n",
      "162 of 257 done...\n",
      "163 of 257 done...\n",
      "164 of 257 done...\n",
      "165 of 257 done...\n",
      "166 of 257 done...\n",
      "167 of 257 done...\n",
      "168 of 257 done...\n",
      "169 of 257 done...\n",
      "170 of 257 done...\n",
      "171 of 257 done...\n",
      "172 of 257 done...\n",
      "173 of 257 done...\n",
      "174 of 257 done...\n",
      "175 of 257 done...\n",
      "176 of 257 done...\n",
      "177 of 257 done...\n",
      "178 of 257 done...\n",
      "179 of 257 done...\n",
      "180 of 257 done...\n",
      "181 of 257 done...\n",
      "182 of 257 done...\n",
      "183 of 257 done...\n",
      "184 of 257 done...\n",
      "185 of 257 done...\n",
      "186 of 257 done...\n",
      "187 of 257 done...\n",
      "188 of 257 done...\n",
      "189 of 257 done...\n",
      "190 of 257 done...\n",
      "191 of 257 done...\n",
      "192 of 257 done...\n",
      "193 of 257 done...\n",
      "194 of 257 done...\n",
      "195 of 257 done...\n",
      "196 of 257 done...\n",
      "197 of 257 done...\n",
      "198 of 257 done...\n",
      "199 of 257 done...\n",
      "200 of 257 done...\n",
      "201 of 257 done...\n",
      "202 of 257 done...\n",
      "203 of 257 done...\n",
      "204 of 257 done...\n",
      "205 of 257 done...\n",
      "206 of 257 done...\n",
      "207 of 257 done...\n",
      "208 of 257 done...\n",
      "209 of 257 done...\n",
      "210 of 257 done...\n",
      "211 of 257 done...\n",
      "212 of 257 done...\n",
      "213 of 257 done...\n",
      "214 of 257 done...\n",
      "215 of 257 done...\n",
      "216 of 257 done...\n",
      "217 of 257 done...\n",
      "218 of 257 done...\n",
      "219 of 257 done...\n",
      "220 of 257 done...\n",
      "221 of 257 done...\n",
      "222 of 257 done...\n",
      "223 of 257 done...\n",
      "224 of 257 done...\n",
      "225 of 257 done...\n",
      "226 of 257 done...\n",
      "227 of 257 done...\n",
      "228 of 257 done...\n",
      "229 of 257 done...\n",
      "230 of 257 done...\n",
      "231 of 257 done...\n",
      "232 of 257 done...\n",
      "233 of 257 done...\n",
      "234 of 257 done...\n",
      "235 of 257 done...\n",
      "236 of 257 done...\n",
      "237 of 257 done...\n",
      "238 of 257 done...\n",
      "239 of 257 done...\n",
      "240 of 257 done...\n",
      "241 of 257 done...\n",
      "242 of 257 done...\n",
      "243 of 257 done...\n",
      "244 of 257 done...\n",
      "245 of 257 done...\n",
      "246 of 257 done...\n",
      "247 of 257 done...\n",
      "248 of 257 done...\n",
      "249 of 257 done...\n",
      "250 of 257 done...\n",
      "251 of 257 done...\n",
      "252 of 257 done...\n",
      "253 of 257 done...\n",
      "254 of 257 done...\n",
      "255 of 257 done...\n",
      "256 of 257 done...\n",
      "Total clipped length = 15290.386236\n",
      "---------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m celltype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL5tt\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Layer 5 thick-tufted\u001b[39;00m\n\u001b[1;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manatomical_constraints\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center.hoc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_singlecell_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellTypeName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcelltype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrOfSamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# <--- Increase this number to get more samples. 50 is sufficient for convergence, but 2 is faster\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# adapt the path, if you have generated a new anatomical model\u001b[39;00m\n\u001b[1;32m     12\u001b[0m path_to_anatomical_model \u001b[38;5;241m=\u001b[39m db[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manatomical_constraints\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center_synapses_20150504-1611_10389\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/singlecell_input_mapper/map_singlecell_inputs.py:257\u001b[0m, in \u001b[0;36mmap_singlecell_inputs\u001b[0;34m(cellName, cellTypeName, nrOfSamples, numberOfCellsSpreadsheetName, connectionsSpreadsheetName, ExPSTDensityName, InhPSTDensityName, boutonDensityFolderName)\u001b[0m\n\u001b[1;32m    255\u001b[0m inputMapper\u001b[38;5;241m.\u001b[39mexCellTypes \u001b[38;5;241m=\u001b[39m exTypes\n\u001b[1;32m    256\u001b[0m inputMapper\u001b[38;5;241m.\u001b[39minhCellTypes \u001b[38;5;241m=\u001b[39m inhTypes\n\u001b[0;32m--> 257\u001b[0m \u001b[43minputMapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_network_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcellName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboutonDensities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrOfSamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrOfSamples\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m endTime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    262\u001b[0m duration \u001b[38;5;241m=\u001b[39m (endTime \u001b[38;5;241m-\u001b[39m startTime) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60.0\u001b[39m\n",
      "File \u001b[0;32m/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/singlecell_input_mapper/singlecell_input_mapper/network_embedding.py:111\u001b[0m, in \u001b[0;36mNetworkMapper.create_network_embedding\u001b[0;34m(self, postCellName, boutonDensities, nrOfSamples)\u001b[0m\n\u001b[1;32m    109\u001b[0m anatomical_areas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcells\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    110\u001b[0m preCellTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcells[anatomical_areas[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 111\u001b[0m cellTypeSynapseDensities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_precompute_anatomical_area_celltype_synapse_densities\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboutonDensities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m sampleConnectivityData \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    114\u001b[0m cellTypeSpecificPopulation \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/singlecell_input_mapper/singlecell_input_mapper/network_embedding.py:370\u001b[0m, in \u001b[0;36mNetworkMapper._precompute_anatomical_area_celltype_synapse_densities\u001b[0;34m(self, boutonDensities)\u001b[0m\n\u001b[1;32m    365\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    366\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing synapse densities from cell type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in anatomical_area \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    367\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(preCellType, anatomical_area))\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m boutons \u001b[38;5;129;01min\u001b[39;00m boutonDensities[anatomical_area][preCellType]:\n\u001b[1;32m    369\u001b[0m             synapseDensities[anatomical_area][preCellType]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 370\u001b[0m                 \u001b[43msynapseDensityComputation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_synapse_density\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mboutons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreCellType\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    372\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m synapseDensities\n",
      "File \u001b[0;32m/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/singlecell_input_mapper/singlecell_input_mapper/synapse_mapper.py:332\u001b[0m, in \u001b[0;36mcompute_synapse_density\u001b[0;34m(self, boutonDensity, preCellType)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(z_start, z_end \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    331\u001b[0m     ijk \u001b[38;5;241m=\u001b[39m i, j, k\n\u001b[0;32m--> 332\u001b[0m     voxelCenter \u001b[38;5;241m=\u001b[39m synapseDensity[anatomical_area]\u001b[38;5;241m.\u001b[39mget_voxel_center(ijk)\n\u001b[1;32m    333\u001b[0m     boutons \u001b[38;5;241m=\u001b[39m boutonDensity\u001b[38;5;241m.\u001b[39mget_scalar(voxelCenter)\n\u001b[1;32m    334\u001b[0m     normPST \u001b[38;5;241m=\u001b[39m normPSTDensity\u001b[38;5;241m.\u001b[39mget_scalar(voxelCenter)\n",
      "File \u001b[0;32m/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/singlecell_input_mapper/singlecell_input_mapper/scalar_field.py:122\u001b[0m, in \u001b[0;36mScalarField.get_scalar\u001b[0;34m(self, xyz)\u001b[0m\n\u001b[1;32m    120\u001b[0m x, y, z \u001b[38;5;241m=\u001b[39m xyz\n\u001b[1;32m    121\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0e-6\u001b[39m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboundingBox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboundingBox[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m delta:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Computing it yourself (this takes some time): --------------------\n",
    "celltype = 'L5tt'  # Layer 5 thick-tufted\n",
    "path = db['anatomical_constraints'].join(\n",
    "    '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center.hoc')\n",
    "I.map_singlecell_inputs(\n",
    "    cellName=path, \n",
    "    cellTypeName=celltype,\n",
    "    nrOfSamples=2  # <--- Increase this number to get more samples. 50 is sufficient for convergence, but 2 is faster\n",
    "    )\n",
    "\n",
    "# adapt the path, if you have generated a new anatomical model\n",
    "path_to_anatomical_model = db['anatomical_constraints'].join(\n",
    "    '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center_synapses_20150504-1611_10389')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed result: --------------------\n",
    "from distutils.dir_util import copy_tree\n",
    "dirname = '86_L5_CDK20041214_nr3L5B_dend_PC_neuron_transform_registered_C2center_synapses_20150504-1611_10389'\n",
    "path_to_anatomical_model = I.os.path.join(getting_started_dir, 'example_data', 'anatomical_constraints', dirname, dirname)\n",
    "silent = copy_tree(path_to_anatomical_model, db['anatomical_constraints'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to parallelize the generation of anatomical models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a distributed [`distributed.Client`](https://distributed.dask.org/en/latest/client.html) to create our `.syn` and `.con` files for one morphology per process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = I.get_client(timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "print(psutil.cpu_count(logical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphology_paths = [db['anatomical_constraints'].join(f) for f in db['anatomical_constraints'].listdir() if f.endswith('.hoc')]\n",
    "morphology_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes as long as creating an anatomical realization for a single cell, but thanks to parallellization, not much longer than that. At least, until the amount of cells exceed the amount of available threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_map_singlecell_inputs = I.dask.delayed(I.map_singlecell_inputs)  # make the single cell mapper a delayed function\n",
    "delayeds = [delayed_map_singlecell_inputs(p, 'L5tt') for p in morphology_paths] # call it with the morphologies\n",
    "delayeds = I.dask.delayed(delayeds) # bundle everything in one delayed object\n",
    "futures = client.compute(delayeds)  # compute the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can restart the client to interrupt this computation if don't want to compute this right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by visualizing the locations of the somata to get a sense of our network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = []\n",
    "cell_types = []\n",
    "\n",
    "somata = I.pd.read_csv(\n",
    "    db[\"anatomical_constraints\"].join(\"presynaptic_somata/presynaptic_somata_soma_locations.csv\"), \n",
    "    skiprows=[0,1,2,3],\n",
    "    header=None,\n",
    "    delimiter=\"\\t\",\n",
    "    names=['Type', 'cell ID', 'x', 'y', 'z']\n",
    "    )\n",
    "somata[['cell_type', 'column']] = somata['Type'].str.split('_', n=1, expand=True)\n",
    "somata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "I.plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = I.plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "fig.patch.set_facecolor(ax.get_facecolor())\n",
    "ax.view_init(azim=60, elev=40)\n",
    "ax.grid(False)\n",
    "\n",
    "for column, pts in somata.sample(2000).groupby(\"column\"):\n",
    "    x, y, z = pts[[\"x\", \"y\", \"z\"]].values.T\n",
    "    ax.scatter(\n",
    "        x, y, z, \n",
    "        label=column)\n",
    "\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(1, 0.5), \n",
    "    loc='center left', \n",
    "    frameon=False, \n",
    "    ncol=2,\n",
    "    title=\"Column\")\n",
    "I.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = I.plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "fig.patch.set_facecolor(ax.get_facecolor())\n",
    "ax.view_init(azim=40, elev=40)\n",
    "ax.grid(False)\n",
    "\n",
    "for cell_type, pts in somata.sample(2000).groupby(\"cell_type\"):\n",
    "    x, y, z = pts[[\"x\", \"y\", \"z\"]].values.T\n",
    "    ax.scatter(\n",
    "        x, y, z,\n",
    "        label=cell_type)\n",
    "\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(1, 0.5), \n",
    "    loc='center left', \n",
    "    frameon=False, \n",
    "    ncol=2,\n",
    "    title=\"Cell type\")\n",
    "I.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the directory generated by the singlecell_input_mapper, there are the following files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['anatomical_constraints'].listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important files for making single-cell simulations are the `.con` file and the `.syn` file. These files are the relevant output of the `SingleCellMapper` for simulations of evoked activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.con` file maps presynaptic cells to a synapse. Not just a celltype, but all individual cells with a specific `cell ID` are mapped to an individual synapse with `synase ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_file = db['anatomical_constraints'].get_file('.con')\n",
    "con_file_path = db['anatomical_constraints'].join(con_file)\n",
    "con_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(con_file_path) as f:\n",
    "    print(f.read()[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.syn` file specifies the exact position of each synapse on the hoc morphology:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_file_path = db['anatomical_constraints'].join(db['anatomical_constraints'].get_file('.syn'))\n",
    "with open(syn_file_path) as f:\n",
    "    print(f.read()[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, section referes to the ID of the section in the cell object. x specifies, where along that section the synapse is placed. If x is 0, this is the beginning of the section, if x is one, this is the end of the section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This setup now covered all the necessary conditions to run a simulations where individual synapses are activated and evoke PSPs onto a taret neuron. See [the next notebook](./2.2%20Network%20activity.ipynb) on how to generate synaptic activations for these synapses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
