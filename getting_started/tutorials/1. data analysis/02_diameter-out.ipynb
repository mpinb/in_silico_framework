{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diameter reconstruction\n",
    "\n",
    "Estimating diameters of image data can be challenging. In the [example data directory](../radii/data/neuron1), we provide image data of L5PTs. These neurons have a long and thick dendrite oriinating from the apiex of the soma, aptly called the \"apical\" dendrite. The slices are cut perpendicular to this dendrite, making it hard to estimate its diameter: the difference between a corkscrewing apical dendrite and a straight and thick apical dendrite is virtually indistinguishable for many conventional microscope resolutions. The other dendrites aren't necessarily easy to reconstruct with diameters either.\n",
    "\n",
    "This example notebook will guide the user through the module [dendrite_thickness](../../../dendrite_thickness/__init__.py). This module uses a rayburst algorithm to estimate the thickness of the dendrites at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T17:47:14.519467Z",
     "iopub.status.busy": "2024-03-06T17:47:14.519021Z",
     "iopub.status.idle": "2024-03-06T17:47:14.520863Z",
     "shell.execute_reply": "2024-03-06T17:47:14.521276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell inserted during automated execution.\n",
    "timeout = 18000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T17:47:14.525188Z",
     "iopub.status.busy": "2024-03-06T17:47:14.524779Z",
     "iopub.status.idle": "2024-03-06T17:47:33.653793Z",
     "shell.execute_reply": "2024-03-06T17:47:33.653276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ISF: Current version: heads/mdb_compatibility+0.gaad1570a.dirty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ISF: Current pid: 41917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to connect to distributed locking server {'config': {'hosts': 'somalogin02-hs:33333'}, 'type': 'zookeeper'}\n",
      "success!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no DISPLAY environment variable.\n",
      "--No graphics will be displayed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mechanisms:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'data_base.db_initializers.load_simrun_general' has no attribute 'load_param_files_from_mdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mInterface\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mI\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgetting_started\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getting_started_dir\n\u001b[1;32m      4\u001b[0m current_dir \u001b[38;5;241m=\u001b[39m I\u001b[38;5;241m.\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(getting_started_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtutorials\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. data analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/Interface.py:143\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_base\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb_initializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_simrun_general \u001b[38;5;28;01mas\u001b[39;00m db_init_simrun_general\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdata_base\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb_initializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m synapse_activation_binning \u001b[38;5;28;01mas\u001b[39;00m mdb_init_synapse_activation_binning\n\u001b[0;32m--> 143\u001b[0m load_param_files_from_mdb \u001b[38;5;241m=\u001b[39m \u001b[43mdb_init_simrun_general\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_param_files_from_mdb\u001b[49m\n\u001b[1;32m    144\u001b[0m load_initialized_cell_and_evokedNW_from_mdb \u001b[38;5;241m=\u001b[39m db_init_simrun_general\u001b[38;5;241m.\u001b[39mload_initialized_cell_and_evokedNW_from_mdb\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m#for compatibility, deprecated!\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'data_base.db_initializers.load_simrun_general' has no attribute 'load_param_files_from_mdb'"
     ]
    }
   ],
   "source": [
    "import Interface as I\n",
    "\n",
    "from getting_started import getting_started_dir\n",
    "current_dir = I.os.path.join(getting_started_dir, \"tutorials\", \"1. data analysis\")\n",
    "DATA_DIR = I.os.path.join(getting_started_dir, \"radii\", \"data\", \"neuron1\")\n",
    "\n",
    "am_folder_path = I.os.path.join(DATA_DIR, 'am')\n",
    "tif_folder_path = I.os.path.join(DATA_DIR, 'tif', 'max_z_projections')\n",
    "hoc_file_path = I.os.path.join(DATA_DIR, 'hoc', '500_GP_WR639_cell_1547_SP5C_checked_RE.hoc')\n",
    "output_folder_path = I.os.path.join(DATA_DIR, 'output')\n",
    "bijective_points_path = I.os.path.join(DATA_DIR, 'landmark', 'am2_transformed_landmark.landmarkAscii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data\n",
    "\n",
    "Let's start by loading in some image scan from the microscope and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_paths = glob.glob(I.os.path.join(tif_folder_path, '*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(img, factor):\n",
    "    x, y = I.np.shape(img)\n",
    "    cut_x, cut_y = x % factor, y % factor\n",
    "    if cut_x:\n",
    "        img = img[:-cut_x]\n",
    "    if cut_y:\n",
    "        img = img[:,:-cut_y]\n",
    "    small_image = img.reshape(\n",
    "        (x//factor, factor, y//factor, factor)).max(3).max(1)\n",
    "    return small_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b1b99926d30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "downsample_factor = 10  # downsample by quite a lot for image stack\n",
    "downsampled_image = downsample(I.np.array(Image.open(image_paths[20])), factor=downsample_factor)\n",
    "I.plt.matshow(downsampled_image, cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the entire image stack look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_image_stack_animation(image_paths, z_coordinates, title=''):\n",
    "    \"\"\"\n",
    "    Given an array of image paths and z coordinates, construct a plotly.Figure() object that you can slide through\n",
    "    based on: https://plotly.com/python/visualizing-mri-volume-slices/ \n",
    "    by Emilia Petrisor\n",
    "        X: @mathinpython\n",
    "        Github: empet\n",
    "    \n",
    "    Args:\n",
    "        image_paths ([str]): array of image paths\n",
    "        z_coordinates ([float|int]): array of z coordinates\n",
    "    \"\"\"\n",
    "    vol = [downsample(io.imread(image), 10) for image in image_paths]\n",
    "    zs = [float(e.split(I.os.sep)[-1][1:3]) for e in image_paths]\n",
    "    r, c = vol[0].shape\n",
    "    nb_frames = len(vol)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        frames=[go.Frame(\n",
    "            data=go.Surface(\n",
    "                z=zs[k] * I.np.ones((r, c)),\n",
    "                surfacecolor=I.np.flipud(vol[nb_frames - k - 1])),\n",
    "            name=str(k))\n",
    "        for k in range(nb_frames)])\n",
    "\n",
    "    # Add data to be displayed before animation starts\n",
    "    fig.add_trace(go.Surface(\n",
    "        z=zs[0] * I.np.ones((r, c)),\n",
    "        surfacecolor=I.np.flipud(vol[0]),\n",
    "        colorscale='Greys_r',\n",
    "        colorbar=dict(thickness=20, ticklen=4)))\n",
    "\n",
    "\n",
    "    def frame_args(duration):\n",
    "        return {\n",
    "                \"frame\": {\"duration\": duration},\n",
    "                \"mode\": \"immediate\",\n",
    "                \"fromcurrent\": True,\n",
    "                \"transition\": {\"duration\": duration, \"easing\": \"linear\"}}\n",
    "\n",
    "    sliders = [\n",
    "                {\n",
    "                    \"pad\": {\"b\": 10, \"t\": 60},\n",
    "                    \"len\": 0.9,\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0,\n",
    "                    \"steps\": [\n",
    "                        {\n",
    "                            \"args\": [[f.name], frame_args(0)],\n",
    "                            \"label\": str(k),\n",
    "                            \"method\": \"animate\",\n",
    "                        } for k, f in enumerate(fig.frames)]}]\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "             title=title,\n",
    "             width=600,\n",
    "             height=600,\n",
    "             scene=dict(\n",
    "                        zaxis=dict(range=[min(zs), max(zs)], autorange=False),\n",
    "                        aspectratio=dict(x=1, y=1, z=1)),\n",
    "             updatemenus = [\n",
    "                {\n",
    "                    \"buttons\": [\n",
    "                        {\n",
    "                            \"args\": [None, frame_args(50)],\n",
    "                            \"label\": \"&#9654;\", # play symbol\n",
    "                            \"method\": \"animate\"},\n",
    "                        {\n",
    "                            \"args\": [[None], frame_args(0)],\n",
    "                            \"label\": \"&#9724;\", # pause symbol\n",
    "                            \"method\": \"animate\"}],\n",
    "                    \"direction\": \"left\",\n",
    "                    \"pad\": {\"r\": 10, \"t\": 70},\n",
    "                    \"type\": \"buttons\",\n",
    "                    \"x\": 0.1,\n",
    "                    \"y\": 0}],\n",
    "             sliders=sliders)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "image_paths.sort()\n",
    "cut_heights = [float(e.split(I.os.sep)[-1][1:3]) for e in image_paths]  # image paths begin with Sxx, where xx is the z-co\n",
    "\n",
    "fig_slider = get_image_stack_animation(\n",
    "    image_paths=image_paths, \n",
    "    z_coordinates=cut_heights,\n",
    "    title='Z-projected images of $50 \\mu m$ thick Wistar rat barrel cortex slices')\n",
    "fig_slider.write_html(I.os.path.join(current_dir, 'static', 'slices.html'), auto_open=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This writes out a `.html` file that you can open in your browser, or a separate tab in Jupyter Lab. Depending on which program you're running, you can also render it inline in the notebook, although you may have to override the default plotly renderer for that. Check available renderers with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Renderers configuration\n",
       "-----------------------\n",
       "    Default renderer: 'plotly_mimetype+notebook'\n",
       "    Available renderers:\n",
       "        ['plotly_mimetype', 'jupyterlab', 'nteract', 'vscode',\n",
       "         'notebook', 'notebook_connected', 'kaggle', 'azure', 'colab',\n",
       "         'cocalc', 'databricks', 'json', 'png', 'jpeg', 'jpg', 'svg',\n",
       "         'pdf', 'browser', 'firefox', 'chrome', 'chromium', 'iframe',\n",
       "         'iframe_connected', 'sphinx_gallery', 'sphinx_gallery_png']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created this notebook with the Jupyter server running on a remote machine, so the renderer is set to \"iframe_connected\". You should adapt this value depending on your Jupyter setup, and IDE (if you're using one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_renderer = \"iframe_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"620px\"\n",
       "    height=\"620\"\n",
       "    src=\"iframe_figures/figure_29.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iframe_connected is recommended if your jupyter server is\n",
    "# not running on the same machine as the program rendering the data\n",
    "fig_slider.show(renderer=plotly_renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaged slices to morphological reconstruction \n",
    "\n",
    "Making a morphological reconstruction from this slice data can be done in two consecutive processes:\n",
    "1. Creating a skeleton of connected dendrites form the slice data\n",
    "2. Assigning diameters to this skeletonized reconstruction\n",
    "\n",
    "The entire pipeline that takes care of both these processes is conveniently bundled under [`thickness.pipeline`](../../../dendrite_thickness/thickness/pipeline.py)\n",
    "\n",
    "We will first run the pipeline in its entirety, and then highlight key steps and how they work one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image slice to skeleton\n",
    "\n",
    "There is a variety of deprojection algorithms that take in a 2D image and deproject it onto a skeleton. We used the Amira extension \"The Filament Editor\" [(Dercksen et al., 2014)](https://link.springer.com/article/10.1007/s12021-013-9213-2#citeas).\n",
    "\n",
    "<center><img src=./static/Dercksen.webp></center>\n",
    "\n",
    "Connecting edges at a branching point. **a** Axonal fragments (black arrow), whose 3D configuration is difficult to identify from the 2D MIP. **b** Even when displaying the position labels, the correct configuration remains ambiguous in 2D. **c** Rotation of the camera immediately reveals the three-dimensional configuration of the fragments. **d** After splicing axonal fragments (magenta segments) and removal of false segmentation results, branches may have to be connected at branching points (one such point is indicated by the arrow). **e** Close-up of the region pointed at by the arrow in d. Nodes are displayed as circles, edge points as small squares. The edge point to be turned into a branching node and the terminal node of the upper edge are selected and (**f**) spliced, resulting in a point-to-node conversion and a new edge connecting the selected node with the new branching node. **g** The reconstruction result superimposed onto the MIP, and (**h**) viewed in 3D. Image and caption taken from [(Dercksen et al., 2014)](https://link.springer.com/article/10.1007/s12021-013-9213-2#citeas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Skeleton to morphology reconstruction\n",
    "\n",
    "The aforementioned methods output a skeleton of a neuron. The next challenge is now to assign dendrite diameters to this skeleton. To do this, we use a rayburst algorithm. This algorithm:\n",
    "1. Iterates over pixels that belong to the neuron in each slice\n",
    "2. Finds the nearest brightest pixel, taken to be a referene point in the neuronal structure in the slice\n",
    "3. Draws various brightness profiles in all directions\n",
    "4. Calculates the least wide brightness profile. This width is then taken to be the diameter of the structure at that pixel.\n",
    "\n",
    "We will illustrate this algorithm by first running the entire pipeline on all slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading hoc file /gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/getting_started/radii/data/neuron1/hoc/500_GP_WR639_cell_1547_SP5C_checked_RE.hoc\n",
      "<Client: 'tcp://10.102.2.83:38786' processes=24 threads=24, memory=2.36 TB>\n"
     ]
    }
   ],
   "source": [
    "from dendrite_thickness.thickness import pipeline\n",
    "\n",
    "# setup the thicnkess pipeline\n",
    "p = pipeline.ExtractThicknessPipeline()\n",
    "p.set_output_path(output_folder_path)\n",
    "p.set_am_paths_by_folder(am_folder_path)  # These amira paths have auto-identified landmarks\n",
    "p.set_tif_paths_by_folder(tif_folder_path)  # slice images\n",
    "p.set_hoc_file(hoc_file_path)  # skeletonized .hoc file\n",
    "p.set_am_to_hoc_transformation_by_landmarkAscii(bijective_points_path)  # not required\n",
    "p.set_client_for_parallelization(client=I.get_client())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- initialize project ----\n",
      "---- setup slice objects ----\n",
      "In threshold: 0.5\n",
      "--------\n",
      "Setting up slice:S36_final_downsampled_dendrites_done_zScale_40_aligned_ascii.am\n",
      "--------\n",
      "Setting up slice:S31_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S32_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S12_final_done_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S35_final_downsampled_dendrites_done_zScale_40_aligned_ascii.am\n",
      "--------\n",
      "Setting up slice:S14_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S26_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S22_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S25_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S17_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S18_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S34_final_downsampled_dendrites_done_zScale_40_ascii.am\n",
      "--------\n",
      "Setting up slice:S35_final_downsampled_dendrites_done_zScale_40_ascii.am\n",
      "--------\n",
      "Setting up slice:S21_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S27_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S30_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S29_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S16_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S20_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S11_final_done_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S23_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S34_final_downsampled_dendrites_done_zScale_40_aligned_ascii.am\n",
      "--------\n",
      "Setting up slice:S28_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S33_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S15_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S36_final_downsampled_dendrites_done_zScale_40_ascii.am\n",
      "--------\n",
      "Setting up slice:S19_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S24_final_done_Alison_zScale_40.am\n",
      "--------\n",
      "Setting up slice:S13_final_done_Alison_zScale_40.am\n",
      "---- extract thicknesses ----\n",
      "---- update slice objects with future values ----\n",
      "---- write am outputs ----\n",
      "---- transform am_points ----\n",
      "---- stacking all slices ----\n",
      "Number of all am_points: 101717\n",
      "---- update hoc file with thicknesses ----\n",
      "time:0.6626255512237549\n",
      "point 1from 13101\n",
      "------------\n",
      "time:0.6640350818634033\n",
      "point 101from 13101\n",
      "------------\n",
      "time:0.6669609546661377\n",
      "point 201from 13101\n",
      "------------\n",
      "time:0.6606976985931396\n",
      "point 301from 13101\n",
      "------------\n",
      "time:0.6550400257110596\n",
      "point 401from 13101\n",
      "------------\n",
      "time:0.6604292392730713\n",
      "point 501from 13101\n",
      "------------\n",
      "time:0.6612534523010254\n",
      "point 601from 13101\n",
      "------------\n",
      "time:0.659203290939331\n",
      "point 701from 13101\n",
      "------------\n",
      "time:0.6605212688446045\n",
      "point 801from 13101\n",
      "------------\n",
      "time:0.6589953899383545\n",
      "point 901from 13101\n",
      "------------\n",
      "time:0.6616272926330566\n",
      "point 1001from 13101\n",
      "------------\n",
      "time:0.6631848812103271\n",
      "point 1101from 13101\n",
      "------------\n",
      "time:0.6610701084136963\n",
      "point 1201from 13101\n",
      "------------\n",
      "time:0.6569287776947021\n",
      "point 1301from 13101\n",
      "------------\n",
      "time:0.6580777168273926\n",
      "point 1401from 13101\n",
      "------------\n",
      "time:0.6608803272247314\n",
      "point 1501from 13101\n",
      "------------\n",
      "time:0.6627988815307617\n",
      "point 1601from 13101\n",
      "------------\n",
      "time:0.6564900875091553\n",
      "point 1701from 13101\n",
      "------------\n",
      "time:0.6596219539642334\n",
      "point 1801from 13101\n",
      "------------\n",
      "time:0.6634485721588135\n",
      "point 1901from 13101\n",
      "------------\n",
      "time:0.660266637802124\n",
      "point 2001from 13101\n",
      "------------\n",
      "time:0.6580066680908203\n",
      "point 2101from 13101\n",
      "------------\n",
      "time:0.6590301990509033\n",
      "point 2201from 13101\n",
      "------------\n",
      "time:0.6624135971069336\n",
      "point 2301from 13101\n",
      "------------\n",
      "time:0.6577274799346924\n",
      "point 2401from 13101\n",
      "------------\n",
      "time:0.6597170829772949\n",
      "point 2501from 13101\n",
      "------------\n",
      "time:0.6641707420349121\n",
      "point 2601from 13101\n",
      "------------\n",
      "time:0.6583230495452881\n",
      "point 2701from 13101\n",
      "------------\n",
      "time:0.6579899787902832\n",
      "point 2801from 13101\n",
      "------------\n",
      "time:0.660825252532959\n",
      "point 2901from 13101\n",
      "------------\n",
      "time:0.6642665863037109\n",
      "point 3001from 13101\n",
      "------------\n",
      "time:0.6630547046661377\n",
      "point 3101from 13101\n",
      "------------\n",
      "time:0.659834623336792\n",
      "point 3201from 13101\n",
      "------------\n",
      "time:0.67372727394104\n",
      "point 3301from 13101\n",
      "------------\n",
      "time:0.654212474822998\n",
      "point 3401from 13101\n",
      "------------\n",
      "time:0.6573052406311035\n",
      "point 3501from 13101\n",
      "------------\n",
      "time:0.6582036018371582\n",
      "point 3601from 13101\n",
      "------------\n",
      "time:0.6587562561035156\n",
      "point 3701from 13101\n",
      "------------\n",
      "time:0.6564366817474365\n",
      "point 3801from 13101\n",
      "------------\n",
      "time:0.6589269638061523\n",
      "point 3901from 13101\n",
      "------------\n",
      "time:0.6629633903503418\n",
      "point 4001from 13101\n",
      "------------\n",
      "time:0.6585323810577393\n",
      "point 4101from 13101\n",
      "------------\n",
      "time:0.6673119068145752\n",
      "point 4201from 13101\n",
      "------------\n",
      "time:0.6614542007446289\n",
      "point 4301from 13101\n",
      "------------\n",
      "time:0.6641359329223633\n",
      "point 4401from 13101\n",
      "------------\n",
      "time:0.6596508026123047\n",
      "point 4501from 13101\n",
      "------------\n",
      "time:0.6587839126586914\n",
      "point 4601from 13101\n",
      "------------\n",
      "time:0.6587622165679932\n",
      "point 4701from 13101\n",
      "------------\n",
      "time:0.6621556282043457\n",
      "point 4801from 13101\n",
      "------------\n",
      "time:0.6605353355407715\n",
      "point 4901from 13101\n",
      "------------\n",
      "time:0.662639856338501\n",
      "point 5001from 13101\n",
      "------------\n",
      "time:0.6604804992675781\n",
      "point 5101from 13101\n",
      "------------\n",
      "time:0.6557552814483643\n",
      "point 5201from 13101\n",
      "------------\n",
      "time:0.6605970859527588\n",
      "point 5301from 13101\n",
      "------------\n",
      "time:0.662898063659668\n",
      "point 5401from 13101\n",
      "------------\n",
      "time:0.6650533676147461\n",
      "point 5501from 13101\n",
      "------------\n",
      "time:0.66013503074646\n",
      "point 5601from 13101\n",
      "------------\n",
      "time:0.6586542129516602\n",
      "point 5701from 13101\n",
      "------------\n",
      "time:0.6577167510986328\n",
      "point 5801from 13101\n",
      "------------\n",
      "time:0.6606595516204834\n",
      "point 5901from 13101\n",
      "------------\n",
      "time:0.664374828338623\n",
      "point 6001from 13101\n",
      "------------\n",
      "time:0.6621041297912598\n",
      "point 6101from 13101\n",
      "------------\n",
      "time:0.6599571704864502\n",
      "point 6201from 13101\n",
      "------------\n",
      "time:0.6648566722869873\n",
      "point 6301from 13101\n",
      "------------\n",
      "time:0.6605129241943359\n",
      "point 6401from 13101\n",
      "------------\n",
      "time:0.6571426391601562\n",
      "point 6501from 13101\n",
      "------------\n",
      "time:0.6632266044616699\n",
      "point 6601from 13101\n",
      "------------\n",
      "time:0.6601653099060059\n",
      "point 6701from 13101\n",
      "------------\n",
      "time:0.6575806140899658\n",
      "point 6801from 13101\n",
      "------------\n",
      "time:0.6557896137237549\n",
      "point 6901from 13101\n",
      "------------\n",
      "time:0.6634566783905029\n",
      "point 7001from 13101\n",
      "------------\n",
      "time:0.6573729515075684\n",
      "point 7101from 13101\n",
      "------------\n",
      "time:0.6567087173461914\n",
      "point 7201from 13101\n",
      "------------\n",
      "time:0.6625206470489502\n",
      "point 7301from 13101\n",
      "------------\n",
      "time:0.6575446128845215\n",
      "point 7401from 13101\n",
      "------------\n",
      "time:0.6594936847686768\n",
      "point 7501from 13101\n",
      "------------\n",
      "time:0.6575949192047119\n",
      "point 7601from 13101\n",
      "------------\n",
      "time:0.6611073017120361\n",
      "point 7701from 13101\n",
      "------------\n",
      "time:0.6601130962371826\n",
      "point 7801from 13101\n",
      "------------\n",
      "time:0.5736510753631592\n",
      "point 7901from 13101\n",
      "------------\n",
      "time:0.49643421173095703\n",
      "point 8001from 13101\n",
      "------------\n",
      "time:0.16636204719543457\n",
      "point 8101from 13101\n",
      "------------\n",
      "time:0.33263301849365234\n",
      "point 8201from 13101\n",
      "------------\n",
      "time:0.3322732448577881\n",
      "point 8301from 13101\n",
      "------------\n",
      "time:0.33215951919555664\n",
      "point 8401from 13101\n",
      "------------\n",
      "time:0.25140953063964844\n",
      "point 8501from 13101\n",
      "------------\n",
      "time:0.41431403160095215\n",
      "point 8601from 13101\n",
      "------------\n",
      "time:0.4099724292755127\n",
      "point 8701from 13101\n",
      "------------\n",
      "time:0.4908151626586914\n",
      "point 8801from 13101\n",
      "------------\n",
      "time:0.41141748428344727\n",
      "point 8901from 13101\n",
      "------------\n",
      "time:0.33185720443725586\n",
      "point 9001from 13101\n",
      "------------\n",
      "time:0.3309061527252197\n",
      "point 9101from 13101\n",
      "------------\n",
      "time:0.4116666316986084\n",
      "point 9201from 13101\n",
      "------------\n",
      "time:0.5798611640930176\n",
      "point 9301from 13101\n",
      "------------\n",
      "time:0.40952515602111816\n",
      "point 9401from 13101\n",
      "------------\n",
      "time:0.32834625244140625\n",
      "point 9501from 13101\n",
      "------------\n",
      "time:0.24699878692626953\n",
      "point 9601from 13101\n",
      "------------\n",
      "time:0.4094982147216797\n",
      "point 9701from 13101\n",
      "------------\n",
      "time:0.4122457504272461\n",
      "point 9801from 13101\n",
      "------------\n",
      "time:0.413867712020874\n",
      "point 9901from 13101\n",
      "------------\n",
      "time:0.4132363796234131\n",
      "point 10001from 13101\n",
      "------------\n",
      "time:0.49262309074401855\n",
      "point 10101from 13101\n",
      "------------\n",
      "time:0.16637730598449707\n",
      "point 10201from 13101\n",
      "------------\n",
      "time:0.3316783905029297\n",
      "point 10301from 13101\n",
      "------------\n",
      "time:0.41417479515075684\n",
      "point 10401from 13101\n",
      "------------\n",
      "time:0.32949399948120117\n",
      "point 10501from 13101\n",
      "------------\n",
      "time:0.24750614166259766\n",
      "point 10601from 13101\n",
      "------------\n",
      "time:0.16442608833312988\n",
      "point 10701from 13101\n",
      "------------\n",
      "time:0.33199024200439453\n",
      "point 10801from 13101\n",
      "------------\n",
      "time:0.246199369430542\n",
      "point 10901from 13101\n",
      "------------\n",
      "time:0.24625849723815918\n",
      "point 11001from 13101\n",
      "------------\n",
      "time:0.32930970191955566\n",
      "point 11101from 13101\n",
      "------------\n",
      "time:0.2498035430908203\n",
      "point 11201from 13101\n",
      "------------\n",
      "time:0.6664266586303711\n",
      "point 11301from 13101\n",
      "------------\n",
      "time:0.6615018844604492\n",
      "point 11401from 13101\n",
      "------------\n",
      "time:0.6621284484863281\n",
      "point 11501from 13101\n",
      "------------\n",
      "time:0.6615719795227051\n",
      "point 11601from 13101\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "df = p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is written to disk, as it can get quite large. Let's read it in and see what kind of information we got out of this pipeline. Pandas operates lazily, so this should not eat up your RAM as long as you don't operate on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dendrite_thickness.thickness.analysis import get_all_data_output_table\n",
    "df = get_all_data_output_table(\n",
    "p.all_slices,\n",
    "p.default_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the z coordinate is relative within the slice. In order to interpret these in a sensible way, we need to infer what the actual z coordinate would be if we were to stack the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z(df, slice_thickness=50):\n",
    "    \"\"\" Given the pipeline output in pandas.DataFrame format, get the height of all points\"\"\"\n",
    "    slice_n = [float(e.split(I.os.sep)[-1][1:3]) for e in df.slice]\n",
    "    point_depths = [z + sn*slice_thickness for z, sn in zip(df.z_slice, slice_n)]\n",
    "\n",
    "    # Slices are from pia to white matter, so low z here means higher up\n",
    "    # Let's reverse that, so high z does not mean high depth, but rather height (makes more sense for a plot)\n",
    "    max_z = slice_thickness*max(slice_n)\n",
    "    point_z = [max_z - e for e in point_depths]\n",
    "    return point_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def get_fig(pipeline):\n",
    "    \"\"\"Given a pipeline object that has run, fetch the output data and construct an interactive plotly 3D scatterplot\"\"\"\n",
    "    df = get_all_data_output_table(\n",
    "        pipeline.all_slices,\n",
    "        pipeline.default_threshold)\n",
    "    \n",
    "    point_z = get_z(df)\n",
    "    fig = px.scatter_3d(\n",
    "        x=df.x_slice, \n",
    "        y=df.y_slice, \n",
    "        z= point_z,\n",
    "        size=df['min_thickness_0.5'].values.tolist(),\n",
    "        color=df['min_thickness_0.5'].values.tolist(),\n",
    "        opacity=0.1\n",
    "    )\n",
    "\n",
    "    # tight layout\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.update_traces(\n",
    "        marker=dict(line=dict(width=0)))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = get_fig(p)\n",
    "fig.show(renderer=\"iframe_connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neuron morphology starts to become visible! However, there are a handful of things that need to be fixed:\n",
    "1. There are a lot of artifacts floating around the neuron that had significant nonzero brightness values in the slice preparation, but are clearly not part of the neuron.\n",
    "2. Cutting the slice preparation introduces a shearing effect near the boundary of the slices, and the points at every 50 $\\mu m$ are misaligned.\n",
    "\n",
    "Both of these things need to be fixed in either pre- or post-processing in e.g. Amira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(I.os.path.join(current_dir, 'static', 'reconstruction.html'), auto_open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = p\n",
    "p2.set_am_paths_by_folder(I.os.path.join(DATA_DIR, 'am_analysis'))\n",
    "p2.set_output_path(I.os.path.join(DATA_DIR, 'output_aligned', data_file))\n",
    "p2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = get_all_data_output_table(\n",
    "p.all_slices,\n",
    "p.default_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = get_fig(p)\n",
    "fig.show(renderer=\"iframe_connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isf3.8",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
