{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the In-Silico Framework (ISF)\n",
    "\n",
    "ISF is a multi-scale simulation environment for the generation, simulation, and analysis of neurobiologically tractable single cell and network-level simulations.\n",
    "\n",
    "![organigram.png](../docs/_static/organigram@300x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "To install ISF (assuming you have already cloned the repository), navigate to the [installer directory](../install). there, you will find installation guides for the simulation environment NEURON, as well as ISF installation scripts for three Python versions: [py2.7](../installer/py2.7/), [py3.8](../installer/py3.8/) and [py3.9](../installer/py3.9/). Navigate to the folder you would like to install and run the containing installation script as outlined below. This will:\n",
    "-  install Anaconda\n",
    "- conda packages\n",
    "- pip packages\n",
    "- install/patch pandas-msgpack (only for py3.8 and py3.9)\n",
    "- patch pandas (only for py2.7)\n",
    "- install an associated ipykernel\n",
    "- compile the [NEURON mechanisms](../mechanisms) used in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    ">>> [user@localhost home]  cd in_silico_framework/install/py3.8\n",
    ">>> [user@localhost py3.8] ./install.sh\n",
    "\n",
    "Enter the directory in which the Anaconda environment should be installed: some-absolute-path/anaconda_isf3.8\n",
    "\n",
    "0/6. Preliminary checks ----------------------------------------------------------------------------\n",
    "Found Anaconda installer in installer/downloads\n",
    "No conda packages found in downloads/conda_packages. They will be downloaded.\n",
    "Warning: found PyPI packages in downloads/pip_packages. They will not be redownloaded. If you have changed the pip_requirements.txt file, you should remove this folder or its contents before attemtping a reinstall.\n",
    "\n",
    "1/6. Installing Anaconda ---------------------------------------------------------------------------\n",
    "\n",
    "Anaconda will be installed in: some-absolute-path/anaconda_isf3.8\n",
    "PREFIX=some-absolute-path/anaconda_isf3.8\n",
    "Unpacking payload ...\n",
    "Collecting package metadata (current_repodata.json): done                                                                                                                                                                       \n",
    "Solving environment: done\n",
    "\n",
    "## Package Plan ##\n",
    "\n",
    "  environment location: /gpfs/soma_fs/scratch/meulemeester/test\n",
    "\n",
    "  added / updated specs:\n",
    "  ...\n",
    "\n",
    "2/6. Installing conda dependencies -----------------------------------------------------------------\n",
    "\n",
    "No conda packages to download.\n",
    "Installing In-Silico-Framework conda dependencies.\n",
    "Preparing transaction: ...working... done\n",
    "Verifying transaction: ...working... done\n",
    "Executing transaction: ...working... done\n",
    "\n",
    "3/6. Installing PyPI dependencies ------------------------------------------------------------------\n",
    "\n",
    "Installing In-Silico-Framework pip dependencies.\n",
    "Looking in links: /gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/installer/py3.8/downloads/pip_packages\n",
    "...\n",
    "\n",
    "4/6. Installing & patching pandas-msgpack ----------------------------------------------------------\n",
    "...\n",
    "\n",
    "5/6. Installing the ipykernel ----------------------------------------------------------------------\n",
    "\n",
    "Installed kernelspec base in /gpfs/soma_fs/home/meulemeester/.local/share/jupyter/kernels/base\n",
    "\n",
    "6/6. Compiling NEURON mechanisms -------------------------------------------------------------------\n",
    "\n",
    "Compiling NEURON mechanisms.\n",
    "...\n",
    "\n",
    "Succesfully installed In-Silico-Framework for Python 3.8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages in ISF\n",
    "\n",
    "### Packages in this repository you will most likely directly interact with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**singlecell_input_mapper**: Module for generating anatomical models, i.e. determining number and location of synapses and number and location of presynaptic cells\n",
    "\n",
    "**single_cell_parser**: High level interface to the NEURON simulator providing methods to perform single cell simulations with synaptic input. The anatomical constraints of the synaptic input are provided by the single_cell_input_mapper module.\n",
    "\n",
    "**simrun**: High level interface to the single_cell_parser module providing methods for common simulation tasks. It also provides methods for building reduced models mimicing the full compartmental model.\n",
    "\n",
    "**data_base**: Flexible database whose API mimics a python dictionary. It provides efficient and scalable methods to store and access simulation results at a terrabyte scale. It also generates metadata, indicating when the data was put in the database and the exact version of the in_silico_framework that was used at this timepoint. Simulation results from the single_cell_parser module can be imported and converted to a high performance binary format. Afterwards the data is accessible using the pandas data analysis library and dask. \n",
    "\n",
    "**single_cell_analyzer**: Library for analysis of single_cell_parser results. Use this module, if you specifically want to analyze a single simulation run. If you want to analyze the results of many simulation trails, the recomended way is to import the simulation results in a model_data_base and use pandas and dask for the analysis afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mechanisms**: NEURON mechanisms (Ion channels, synapses, ...) used by the neuron simulator. If you run `import mechanisms`, these mechanisms are beeing compiled. Make sure, that you have the nrnivmodl executable in your path, otherwise this will not work\n",
    "\n",
    "**tests**: Pytest tests for the respective modules. To run the testsuite, use `pytest tests/`. Keep in mind that some tests need a dask service in order to work. If you have started a dask-service, you shou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How should I interact with these packages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended way is to use the `Interface` module which glues together all these packages mentioned above to one *Application*: It provides the API necessary to perform simulation tasks and provides additional methods that improve interactivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying to connect to distributed locking server {'type': 'file'}\n",
      "[WARNING] ISF.isf_data_base.distributed_lock: Using file based locking. Please be careful on nfs mounts as file based locking has issues in this case.\n",
      "Current version: heads/publish+0.ga1c216d2.dirty\n",
      "Current pid: 129055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no DISPLAY environment variable.\n",
      "--No graphics will be displayed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mechanisms:\n",
      "\n",
      "\n",
      "Loaded modules with __version__ attribute are:\n",
      "IPython: 8.12.3, Interface: heads/publish+0.ga1c216d2.dirty, PIL: 8.2.0, _csv: 1.0, _ctypes: 1.1.0, _curses: b'2.2', _decimal: 1.70, argparse: 1.1, attr: 20.3.0, backcall: 0.2.0, blake3: 0.3.3, blosc: 1.10.2, bluepyopt: 1.9.126, bottleneck: 1.3.2, cffi: 1.14.3, click: 7.1.2, cloudpickle: 1.6.0, colorama: 0.4.4, comm: 0.2.1, csv: 1.0, ctypes: 1.1.0, cycler: 0.10.0, cytoolz: 0.11.0, dash: 2.9.3, dask: 2.30.0, dateutil: 2.8.2, deap: 1.3, debugpy: 1.8.0, decimal: 1.70, decorator: 4.4.2, distributed: 2.30.1, distutils: 3.8.5, executing: 2.0.1, filelock: 3.0.12, flask: 1.1.2, flask_cors: 4.0.0, frozendict: 2.3.8, fsspec: 0.8.3, future: 0.18.2, gevent: 20.9.0, greenlet: 0.4.17, ipaddress: 1.0, ipykernel: 6.29.0, ipython_genutils: 0.2.0, ipywidgets: 7.5.1, itsdangerous: 1.1.0, jedi: 0.17.1, jinja2: 3.0.3, joblib: 1.3.2, json: 2.0.9, jupyter_client: 8.6.0, jupyter_core: 5.7.1, kiwisolver: 1.3.0, llvmlite: 0.34.0, logging: 0.5.1.2, markupsafe: 2.1.3, matplotlib: 3.3.2, neuron: 7.8.2, numba: 0.51.2, numexpr: 2.7.1, numpy: 1.19.2, packaging: 23.2, pandas: 1.1.3, pandas_msgpack: 0.1.4+14.gfcb0471.dirty, parameters: 0.2.1, parso: 0.7.0, past: 0.18.2, pexpect: 4.8.0, pickleshare: 0.7.5, platform: 1.0.8, platformdirs: 3.11.0, plotly: 5.17.0, prompt_toolkit: 3.0.43, psutil: 5.7.2, ptyprocess: 0.6.0, pure_eval: 0.2.2, pyarrow: 12.0.1, pydantic: 1.10.4, pydevd: 2.9.5, pygments: 2.16.1, pyparsing: 2.4.7, pytz: 2020.1, re: 2.2.1, scandir: 1.10.0, scipy: 1.5.2, seaborn: 0.11.0, six: 1.15.0, sklearn: 1.3.2, socketserver: 0.4, sortedcontainers: 2.2.2, sparse: 0.14.0, stack_data: 0.6.3, statsmodels: 0.12.0, sumatra: 0.7.4, tables: 3.6.1, tabulate: 0.9.0, tblib: 1.7.0, threadpoolctl: 2.1.0, tlz: 0.11.0, toolz: 0.11.1, traitlets: 5.14.1, vaex: {'vaex': '4.16.0', 'vaex-core': '4.16.1', 'vaex-viz': '0.5.4', 'vaex-hdf5': '0.14.1', 'vaex-server': '0.8.1', 'vaex-astro': '0.9.3', 'vaex-jupyter': '0.8.2', 'vaex-ml': '0.18.3'}, wcwidth: 0.2.5, werkzeug: 1.0.1, yaml: 5.3.1, zlib: 1.0, zmq: 25.1.2\n"
     ]
    }
   ],
   "source": [
    "import Interface as I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can access the relevant packages, functions and classes directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting client with ip 10.102.2.81\n",
      "got client <Client: 'tcp://10.102.2.81:38786' processes=24 threads=24, memory=98.30 GB>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'seaborn' from '/gpfs/soma_fs/scratch/meulemeester/anaconda_isf3.8/lib/python3.8/site-packages/seaborn/__init__.py'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "I.scp # single_cell_parser package\n",
    "I.sca # single_cell_analyzer package\n",
    "I.DataBase # main class of isf_data_base\n",
    "I.map_singlecell_inputs # compute anatomical model for a given cell morphology in barrel cortex \n",
    "I.simrun_run_new_simulations # default function for running single cell simulations with well constrained synaptic input\n",
    "I.db_init_simrun_general.init # default method to initialize a model data base with existing simulation results\n",
    "I.db_init_simrun_general.optimize # converts the data to speed optimized compressed binary format\n",
    "I.synapse_activation_binning_dask # parallelized binning of synapse activation data\n",
    "I.rm_get_kernel # create reduced lda model from simulation data\n",
    "\n",
    "I.silence_stdout # context manager and decorator to silence functions\n",
    "I.cache # decorator to cache functions\n",
    "\n",
    "I.get_client(timeout=10) # get distributed.Client() object for parallel execution\n",
    "\n",
    "I.np # numpy\n",
    "I.pd # pandas\n",
    "I.dask # dask\n",
    "I.distributed # distributed\n",
    "I.sns # seaborn\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use autocompletion of IPython to find the other modules. To view the documentation, use a questionamrk, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_init_simrun_general\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msimresult_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvoltage_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msynapse_activation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdendritic_voltage_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mparameterfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mspike_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mburst_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrepartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrewrite_in_optimized_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdendritic_spike_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdendritic_spike_times_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_chunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdumper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;34m'isf_data_base.IO.LoaderDumper.pandas_to_parquet'\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m'/gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/isf_data_base/IO/LoaderDumper/pandas_to_parquet.py'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Use this function to load simulation data generated with the simrun module \n",
      "into a DataBase. \n",
      "\n",
      "After initialization, you can access the data from the isf_data_base in the following manner:\n",
      "db['synapse_activation'], db['cell_activation'], db['voltage_traces'], db['spike_times'], ...\n",
      "Use db.keys() to view all available data.\n",
      "\n",
      "Note that the database does not contain the actual data, instead it contains links \n",
      "to the original / external data.\n",
      "\n",
      "rewrite_in_optimized_format: if True, data is converted to a high performance binary \n",
      "format and makes unpickling more robust against version changes of third party libraries. \n",
      "Also, it makes the database self-containing, i.e. you can move it to another machine or \n",
      "subfolder and everything still works. Deleting the data folder then would (should) not cause \n",
      "loss of data. If False, the db only contains links to the actual simulation data folder \n",
      "and will not work if the data folder is deleted or moved or transferred to another machine \n",
      "where the same absolute paths are not valid.\n",
      "\n",
      "client: dask distributed Client object.\n",
      "\u001b[0;31mFile:\u001b[0m      /gpfs/soma_fs/scratch/meulemeester/project_src/in_silico_framework/isf_data_base/db_initializers/load_simrun_general.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "I.db_init_simrun_general.init?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "\n",
    "The [tutorials](./tutorials) provides various workflows that you can do with ISF, such as benchmarking biophysical models, running simulations of synaptic activations on a biophysically detailed cell, or simulating a network of interconnected reduced models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isf3.8",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
