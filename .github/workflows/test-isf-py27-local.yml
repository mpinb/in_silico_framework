# Installation of in-silico-framework followed by CI tests.
# Builds ISF locally on the MPINB-hosted runner and runs all tests
name: ISF Py 2.7
# Controls when the workflow will run
on:
  push:
    branches: [ 'master' , 'testing' ]
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  
  build:
    name: Build
    uses: ./.github/workflows/build-isf.yml
    with:
      py_version: 2.7

  test:
    name: Test
    needs: build  # assures there is a build of ISF
    # Assure test runs on whatever runner the build ran on
    # Note that runners are requested based on label, not on name
    # So the runner should have a label equal to its name
    runs-on: ${{ needs.build.outputs.runner_name }}
    defaults:
      run:
        shell: bash -l {0}

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      - name: Test ISF for Python 2.7
        run: |
          pkill -U $USER dask-worker
          pkill -U $USER dask-scheduler
          CONDA_TARGET_DIR="$HOME/anaconda_isf2.7"
          source $CONDA_TARGET_DIR/bin/activate
          echo "Using Python: $(which python)"
          export PYTHONPATH=$(pwd):$HOME
          echo $PYTHONPATH

          name=${{ runner.name }}
          runner_number=$( echo $name | grep -Eo '[0-9]+$' )
          port_number=387${runner_number: -1}6
          bokeh_port=387${runner_number: -1}7
          echo "Launching Dask server on $name"
          echo "Using port $port_number and bokeh port $bokeh_port"

          mkdir -p ./tests/logs/

          (dask-scheduler --port=$port_number --bokeh-port=$bokeh_port > ./tests/logs/dask_scheduler_${{ github.run_id }}.log 2>&1)&
          (dask-worker localhost:$port_number --nthreads 1 --nprocs 6 --memory-limit=100e15 > ./tests/logs/dask_workers_${{ github.run_id }}.log 2>&1)&
          python -m pytest -rsx -vv --color=yes tests/

      - name: Cleanup dask orphan processes
        if: ${{ always() }}
        run: |
          pkill -U $USER dask-scheduler
          pkill -U $USER dask-worker

      - name: Save test logs as artifacts
        uses: actions/upload-artifact@v3
        if: ${{ always() }} 
        with:
          name: ${{ github.run_id }}_logs
          path: ./tests/logs/
