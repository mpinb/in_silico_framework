# Installation of in-silico-framework followed by CI tests.
# Builds ISF locally on the MPINB-hosted runner and runs all tests
name: ISF Py3 (local) build/test
# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: '*'
  pull_request:
    branches: [ master ]
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: [ self-hosted, MPINB_test ]
    defaults:
      run:
        shell: bash -l {0}
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v3
      # Install Anaconda3 and update conda package manager
      - name: Install Anaconda3
        run: |
          echo "Downloading Anaconda3-2020.11-Linux-x86_64"
          wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh --quiet
          DIR="$HOME/conda3-isf"
          if [ -d "$DIR" ]; then
            echo "Found existing installation in $HOME. Removing previous Anaconda installation..."
            rm -r "$DIR"
          else
            echo "No previous Anaconda installation found. Continuing..."
          fi
          echo "Installing Anaconda3"
          bash Anaconda3-2020.11-Linux-x86_64.sh -b -p $HOME/conda3-isf
          source $HOME/conda3-isf/bin/activate
          conda info
      # Updating the root environment. Install ISF dependencies (YAML)
      # NOTE: The environment file (yaml) is in the ISF repository 'installer' folder
      - name: Install ISF dependencies
        run: |
          source $HOME/conda3-isf/bin/activate
          echo "Installing 'in silico framework' dependencies."
          conda-env create --name isf-py3 --file installer/env-isf-py3.yml --quiet
          source activate isf-py3
          conda list
          
      # Patch Dask library
      - name: Patch dask library
        run: |
          echo "Patching dask library."
          source $HOME/conda3-isf/bin/activate
          source activate isf-py3
          cd installer
          python patch_dask_linux64.py
          conda list
      # Install pandas-msgpack
      - name: Install pandas-msgpack
        run: |
          echo "Installing pandas-msgpack"
          git clone https://github.com/abast/pandas-msgpack.git
          # Applying patch to pandas-msgpack (generating files using newer Cython)
          git -C pandas-msgpack apply ../installer/pandas_msgpack.patch
          source $HOME/conda3-isf/bin/activate
          source activate isf-py3
          cd pandas-msgpack; python setup.py install
          pip list --format=freeze | grep pandas
          cd ..; rm -r pandas-msgpack
      # Compile neuron mechanisms
      - name: Compile neuron mechanisms
        run: |
          echo "Compiling neuron mechanisms"
          source $HOME/conda3-isf/bin/activate
          source activate isf-py3
          pushd .
          cd mechanisms/channels_py3; nrnivmodl;
          popd
          cd mechanisms/netcon_py3; nrnivmodl
          
      # Run in-silico-framework tests
      - name: Test in-silico-framework
        run: |
          source $HOME/conda3-isf/bin/activate
          source activate isf-py3
          export PYTHONPATH="$(pwd)"
          dask-scheduler --port=38786 --dashboard-address=38787 &
          dask-worker localhost:38786 --nthreads 1 --nprocs 4 --memory-limit=100e15 &
          pytest -rsx -vv --color=yes --cov-report xml:tests/coverage_reports/report_py3.xml --cov=. tests
      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./tests/coverage_reports/report_py3.xml
          verbose: true # optional (default = false)
        
